{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e3d9734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import io\n",
    "import os\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from deepagents import create_deep_agent\n",
    "from deepagents.backends.filesystem import FilesystemBackend\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "\n",
    "import uuid\n",
    "\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "from langchain.tools import tool\n",
    "from langchain_core.messages import HumanMessage, ToolMessage, BaseMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import END, MessageGraph, StateGraph\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db69a815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf5bec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1-mini\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e9cb1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path(r\"C:\\Users\\ANDRES\\Desktop\\RappIntelligence\").resolve()\n",
    "\n",
    "@tool\n",
    "def safe_read_file(file_path: str, limit: int = 2000):\n",
    "    \"\"\"\n",
    "    Lee archivos SOLO dentro de ROOT.\n",
    "    Bloquea rutas absolutas tipo /data/... o C:\\\\...\n",
    "    \"\"\"\n",
    "    p = Path(file_path)\n",
    "\n",
    "    # Bloquear rutas absolutas o que intenten escapar\n",
    "    if p.is_absolute() or \"..\" in p.parts:\n",
    "        return {\"error\": f\"Ruta no permitida: {file_path}\"}\n",
    "\n",
    "    abs_path = (ROOT / p).resolve()\n",
    "\n",
    "    # Verificar que quede dentro de ROOT\n",
    "    if not str(abs_path).startswith(str(ROOT)):\n",
    "        return {\"error\": f\"Ruta fuera del proyecto: {abs_path}\"}\n",
    "\n",
    "    if not abs_path.exists():\n",
    "        return {\"error\": f\"Archivo no encontrado: {abs_path}\"}\n",
    "\n",
    "    with open(abs_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read(limit)\n",
    "\n",
    "    return {\"path\": str(abs_path), \"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d50e62bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#backend = LocalShellBackend(root_dir=str(ROOT), env=os.environ.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b499c5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = InMemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6e750821",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = {\n",
    "    \"name\": \"Cargador_de_archivos\",\n",
    "    \"description\": \"subagente que carga los archivos csv\",\n",
    "    \"system_prompt\": \"\"\"Tu unica tarea es revisar los archivos csv y cargarlos si la solicitud del usuario lo requiere.\n",
    "    No es necesario que siempre cargues todos los archivos, debes evaluar la solicitud del usuario y cargar solo los archivos\n",
    "    que sean necesarios.\"\"\",\n",
    "    \n",
    "    \"tools\": [safe_read_file],\n",
    "    \"model\": \"openai:gpt-4.1-mini\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c544a276",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.utilities import PythonREPL\n",
    "python_repl = PythonREPL()\n",
    "\n",
    "MAX_OUTPUT_CHARS = 3000\n",
    "BLACKLIST_TERMS = [\"import os\", \"import sys\", \"__import__\", \"open(\", \"subprocess\", \"socket\", \"requests\", \"eval(\", \"exec(\", \"os.system\"]\n",
    "\n",
    "@tool\n",
    "def python_repl_tool(code: str) -> str:\n",
    "    \"\"\"\n",
    "    Ejecuta `code` en un REPL con un prelude que expone helpers: load_csv, preview, schema_stats.\n",
    "    Se bloquean patterns peligrosos y se trunca la salida.\n",
    "    \"\"\"\n",
    "    # chequeo blacklist simple\n",
    "    low = code.lower()\n",
    "    for b in BLACKLIST_TERMS:\n",
    "        if b in low:\n",
    "            return f\"ERROR: uso de terminos prohibidos: {b}\"\n",
    "\n",
    "    # PRELUDE: helpers disponibles para el LLM (puede ajustar)\n",
    "    prelude = f'''\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "ROOT = r\"{str(ROOT)}\"\n",
    "\n",
    "def load_csv(name, usecols=None, nrows=None):\n",
    "    p = Path(ROOT) / name\n",
    "    if not str(p.resolve()).startswith(str(Path(ROOT))):\n",
    "        raise Exception(\"ruta fuera del proyecto\")\n",
    "    return pd.read_csv(p, usecols=usecols, nrows=nrows)\n",
    "\n",
    "def preview(name, n=5):\n",
    "    return load_csv(name, nrows=n).to_json(orient=\"records\")\n",
    "\n",
    "def schema_stats(name, n=1000):\n",
    "    df = load_csv(name, nrows=n)\n",
    "    return {{\n",
    "        \"dtypes\": df.dtypes.apply(lambda x: str(x)).to_dict(),\n",
    "        \"nnulls\": df.isna().sum().to_dict(),\n",
    "        \"numeric_sample\": df.select_dtypes(\"number\").agg([\"min\",\"max\",\"mean\"]).to_dict()\n",
    "    }}\n",
    "'''\n",
    "\n",
    "    full_code = prelude + \"\\n\" + code\n",
    "\n",
    "    try:\n",
    "        out = python_repl.run(full_code)\n",
    "        if len(out) > MAX_OUTPUT_CHARS:\n",
    "            return out[:MAX_OUTPUT_CHARS] + \"\\n\\n...[truncated]\"\n",
    "        return out\n",
    "    except Exception as e:\n",
    "        return f\"ERROR: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ad9eefc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_data = {\n",
    "    \"name\": \"Analizador_de_los_datos\",\n",
    "    \"description\": \"subagente que analiza los datos\",\n",
    "    \"system_prompt\": \"\"\"Tu unica tarea es hacer el analisis correspondiente de los datos segun la solicitud del usuario\"\"\",\n",
    "    \n",
    "    \"tools\": [python_repl_tool],\n",
    "    \"model\": \"openai:gpt-4.1-mini\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e54b7069",
   "metadata": {},
   "outputs": [],
   "source": [
    "subagents = [load_data, analysis_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5be1d717",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "Eres un analista de datos con experiencia en análisis de métricas y órdenes.\n",
    "Tu tarea es analizar los datos dependiendo las preguntas que haga el usuario.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "03e67c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANDRES\\AppData\\Local\\Temp\\ipykernel_7936\\1459261890.py:4: DeprecationWarning: FilesystemBackend virtual_mode default will change in deepagents 0.5.0; please specify virtual_mode explicitly. Note: virtual_mode is for virtual path semantics (e.g., CompositeBackend routing) and optional path-based guardrails; it does not provide sandboxing or process isolation. Security note: leaving virtual_mode=False allows absolute paths and '..' to bypass root_dir. Consult the API reference for details.\n",
      "  backend=FilesystemBackend(root_dir=\"C:/Users/ANDRES/Desktop/RappIntelligence\"),\n"
     ]
    }
   ],
   "source": [
    "agent = create_deep_agent(\n",
    "    model=llm,\n",
    "    #tools=[safe_read_file],\n",
    "    backend=FilesystemBackend(root_dir=\"C:/Users/ANDRES/Desktop/RappIntelligence\"),\n",
    "    checkpointer=checkpointer,\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "            model=\"gpt-4.1-mini\",\n",
    "            trigger=(\"tokens\", 10000),\n",
    "            keep=(\"messages\", 20),\n",
    "        ),\n",
    "    ],\n",
    "    interrupt_on={\n",
    "        \"write_file\": True,  # Default: approve, edit, reject\n",
    "        \"read_file\": True,  # No interrupts needed\n",
    "        \"edit_file\": True    # Default: approve, edit, reject\n",
    "    },\n",
    "    subagents=subagents,\n",
    "    system_prompt=system_prompt,\n",
    ")\n",
    "\n",
    "thread_id = str(uuid.uuid4())\n",
    "config={\"configurable\": {\"thread_id\": thread_id}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3bd1cf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": (\"Cuáles son las 5 zonas con mayor % Lead Penetration esta semana\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a4d017da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  task (call_m866fJw4UNxEFrhQ24VZcKuR)\n",
      " Call ID: call_m866fJw4UNxEFrhQ24VZcKuR\n",
      "  Args:\n",
      "    description: Analizar los datos de esta semana para identificar las 5 zonas con mayor porcentaje de Lead Penetration. Se requiere un informe con las zonas ordenadas de mayor a menor porcentaje.\n",
      "    subagent_type: Analizador_de_los_datos\n",
      "TOKENS: {'input_tokens': 5095, 'output_tokens': 60, 'total_tokens': 5155, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: task\n",
      "\n",
      "No he encontrado un archivo específico para los datos de esta semana en los directorios comunes. Por favor, proporcióname el archivo o datos donde pueda realizar el análisis del porcentaje de Lead Penetration por zona para identificar las 5 zonas con mayor porcentaje.\n",
      "TOKENS: None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Para poder analizar y decirte cuáles son las 5 zonas con mayor porcentaje de Lead Penetration esta semana, necesito que me proporciones el archivo o los datos específicos que contienen la información de los leads y su penetración por zona en esta semana. ¿Podrías subir el archivo o indicarme dónde encontrar esos datos?\n",
      "TOKENS: {'input_tokens': 5214, 'output_tokens': 67, 'total_tokens': 5281, 'input_token_details': {'audio': 0, 'cache_read': 5120}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "for step in agent.stream(\n",
    "    {\"messages\": [input_message]},\n",
    "    config,\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    for _, update in step.items():\n",
    "        if update and (\n",
    "            (isinstance(update, dict) and (messages := update.get(\"messages\"))) or\n",
    "            (isinstance(update, tuple) and update[0] == \"messages\" and (messages := update[1]))\n",
    "        ) and isinstance(messages, list):\n",
    "            for message in messages:\n",
    "                message.pretty_print()\n",
    "                print(\"TOKENS:\", getattr(message, \"usage_metadata\", None) or message.additional_kwargs.get(\"usage\", None))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
