<div align="center">
  <img src="data/RappiBot.png" alt="RappIntelligence Bot" width="1020" />
</div>

# ü§ñ RappIntelligence

RappIntelligence es un sistema impulsado por IA dise√±ado para democratizar el acceso a datos. Permite a los equipos consultar m√©tricas operacionales utilizando lenguaje natural a trav√©s de un Bot interactivo, adem√°s de generar automatizadamente reportes estrat√©gicos ejecutivos semanales mediante su motor de Insights.

## üöÄ C√≥mo Ejecutar el Proyecto

### 1. Requisitos Previos

1. Aseg√∫rate de tener instalado Python 3.11 y [uv](https://docs.astral.sh/uv/) (el gestor de dependencias utilizado en el proyecto).
2. Clona el repositorio e instala las dependencias:
   ```bash
   uv sync
   ```
3. Crea un archivo `.env` en la ra√≠z del proyecto para alojar tus credenciales. Necesitar√°s como m√≠nimo:
   ```env
   OPENAI_API_KEY=tu_clave_aqui
   ```
4. Agrega los datos de entrada en la ruta `data/`. Debes tener:
   - `df_metrics.csv`
   - `df_orders.csv`

---

### 2. Ejecutar el Agente Conversacional (Bot)

El bot sirve como una interfaz interactiva donde cualquier usuario puede explorar los datos haciendo preguntas sin necesidad de conocimientos t√©cnicos o SQL.

```bash
uv run python main.py
```
Abre tu navegador web en: **http://localhost:8080** 

- **¬øQu√© puedes analizar?**
  - **Filtros r√°pidos:** *¬øCu√°les son las 5 zonas con mayor Lead Penetration esta semana?*
  - **Comparativas:** *Compara Perfect Order entre zonas Wealthy y Non Wealthy en M√©xico.*
  - **Identificaci√≥n de tendencias:** *Evoluci√≥n de Gross Profit UE en Chapinero.*
  - **Explicaci√≥n de insights:** *¬øQu√© zonas crecen m√°s en √≥rdenes y qu√© lo explica?*

---

### 3. Ejecutar el Generador Executivo de Reportes (Insights)

El m√≥dulo de Insights utiliza un pipeline avanzado (LangGraph ReAct) para analizar cruces de m√©tricas a nivel pa√≠s, ciudad y zona, y emitir recomendaciones t√°cticas fundamentadas.

```bash
uv run python Insights/main.py
```

- **¬øQu√© genera?**
  - El script evaluar√° todo el ecosistema y escribir√° una pieza de narrativa profesional.
  - Podr√°s encontrar el resultado en formato `Reporte_Estrategico_Rappi.md` (Markdown) y `Reporte_Estrategico_Rappi.pdf` (PDF) dentro de la carpeta `Insights/`.
  - *Nota: Para la generaci√≥n y el renderizado correcto del archivo PDF, debes tener `wkhtmltopdf` instalado en tu sistema y referenciado en el proyecto.*

---

- **Bot Principal (`scr/`)**: 
  - **`api.py`**: Servidor FastAPI local.
  - **`agent.py`**: Maneja el flujo interactivo de los usuarios con LangGraph. Utiliza nodos espec√≠ficos (`router`, `semantic_mapper`, `analyst`, `responder`, y `summarizer`). El n√∫cleo anal√≠tico usa `create_pandas_dataframe_agent` interconectado con GPT-4o para interpretar datos. 
  - **Frontend (`static/`)**: Una UI simple en HTML, CSS y JS puro para chat en tiempo real.
- **Insights Pipeline (`Insights/`)**:
  - **`tools_rappi.py`**: Aloja l√≥gicas robustas de an√°lisis con m√©todos como Momentum, Z-score Benchmarking y Riesgo Multivariable cruzando m√©tricas directamente desde DataFrames.
  - **`main.py`**: Implementa Graph de LangGraph (`generation_node` y `reflection_node`) con Prompting estricto orientado a negocios para forzar al LLM a contar una "historia accionable". Finalmente formatea la salida en Markdown/HTML y PDF mediante bibliotecas est√°ndar.

---

## üîç Observabilidad (Langfuse)

El proyecto incluye integraci√≥n profunda con **Langfuse** para ambas secciones (Bot e Insights) de forma que puedas trazar el consumo de tokens, uso de CPU y l√≥gica de toma de decisi√≥n del LLM paso a paso. 

Para habilitarlo, necesitas contar con claves de Langfuse v√°lidas y configurarlas en el `.env`:

```env
# RappIntelligence (Bot)
LANGFUSE_SECRET_KEY="sk-lf-..."
LANGFUSE_PUBLIC_KEY="pk-lf-..."
LANGFUSE_BASE_URL="https://cloud.langfuse.com"

# RappInsights (Insights Pipeline)
LANGFUSE_INSIGHTS_SECRET_KEY="sk-lf-..."
LANGFUSE_INSIGHTS_PUBLIC_KEY="pk-lf-..."
LANGFUSE_INSIGHTS_BASE_URL="https://cloud.langfuse.com"
```

El Bot inyecta su propio `CallbackHandler` de Langfuse por sesi√≥n para registrar las consultas en la interfaz (`scr/observability.py`), mientras que el Pipeline de Insights tiene su propio entorno (separado con el prefijo `_INSIGHTS_`) para registrar la generaci√≥n masiva de an√°lisis e inferencias (`Insights/main.py`).
